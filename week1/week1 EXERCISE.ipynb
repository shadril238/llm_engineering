{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:03:22.087464Z",
     "start_time": "2025-02-03T10:03:20.101586Z"
    }
   },
   "source": [
    "from week1.day5 import system_prompt\n",
    "# imports\n",
    "!ollama pull llama3.2\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import ollama"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[?25lpulling manifest ⠙ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠙ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠹ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠸ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠴ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠴ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠦ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠧ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠏ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest ⠏ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gpulling manifest \r\n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \r\n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \r\n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \r\n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \r\n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \r\n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \r\n",
      "verifying sha256 digest \r\n",
      "writing manifest \r\n",
      "success \u001B[?25h\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:03:29.001707Z",
     "start_time": "2025-02-03T10:03:28.999377Z"
    }
   },
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:10:09.875699Z",
     "start_time": "2025-02-03T10:10:09.866597Z"
    }
   },
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:12:06.022905Z",
     "start_time": "2025-02-03T10:12:06.020339Z"
    }
   },
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = '''\n",
    "    You are an AI-powered technical assistant designed to answer programming and software engineering questions with clear, well-structured explanations. Your responses should be concise yet informative, breaking down complex topics into digestible insights. When relevant, provide code snippets, examples, or analogies to enhance understanding. Maintain a professional yet approachable tone, ensuring explanations are accurate and practical. If a question is ambiguous, assume the most relevant interpretation and respond accordingly. Avoid unnecessary jargon, and aim to make each answer useful for both beginners and experienced developers.\n",
    "'''"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:14:41.325519Z",
     "start_time": "2025-02-03T10:14:41.322485Z"
    }
   },
   "source": [
    "# llama3.2\n",
    "def get_response(question):\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "      ],\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            result += chunk.choices[0].delta.content\n",
    "\n",
    "    return result\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T10:14:56.786459Z",
     "start_time": "2025-02-03T10:14:42.876855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_prompt = input(\"Enter your technical question: \")\n",
    "print(get_response(user_prompt))"
   ],
   "id": "dfbbf0e9a7f31c91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Math problem solved!\n",
      "\n",
      "Of course, the answer is straightforward: 2 + 5 = 7.\n",
      "\n",
      "By the way, I'd love to chat with you about math or programming if you're interested in discussing a specific topic or have any questions!\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ede3127959a3e73"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
